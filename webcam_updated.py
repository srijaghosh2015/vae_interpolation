print("âœ… YASSS")

# -*- coding: utf-8 -*-
"""webcam.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1w-m1_rdu4x1OeHRJIlCBhlO0UxDR2mbv

"""

import cv2

import mediapipe.python.solutions.hands as mp_hands
import mediapipe.python.solutions.drawing_utils as mp_drawing
import mediapipe.python.solutions.drawing_styles as mp_drawing_styles
import asyncio
import websockets
import json
import threading



current_websocket = None
event_loop = None

def draw_grid(dims,screen_height, screen_width, frame):
    crop_padding = (screen_width - screen_height)//2
    
    horizontal_range = (crop_padding, screen_width - crop_padding)
    
    # Cell size
    increment = (horizontal_range[1] - horizontal_range[0]) // dims
    
    # Draw grid lines
    for i in range(dims + 1):
        # Vertical lines
        x =  horizontal_range[0] + i * increment
        cv2.line(frame, (x, 0), (x, screen_height), (0, 255, 0), 2)
        
        # Horizontal lines
        y = i * increment
        cv2.line(frame, (horizontal_range[0], y), (horizontal_range[1], y), (0, 255, 0), 2)

# Main code
cap = cv2.VideoCapture(0)




def coords_to_graph(dims, x, y, screen_height, screen_width):
  crop_padding = (screen_width - screen_height)//2

  horizontal_range = (crop_padding, screen_width - crop_padding)
  vertical_range = (0, screen_height)

  increment = (horizontal_range[1] - horizontal_range[0]) / dims

  if ((x >= horizontal_range[0] and x <= horizontal_range[1]) and (y >= vertical_range[0] and y <= vertical_range[1])):
     # x cell logic --> (dims - (int(x - horizontal_range[0])) - 1
     # y cell logic --> (dims - (int(y - vertical_range[0])) -1 
     cell_x = int((dims - ((x - horizontal_range[0])/increment)))# this is correct
     cell_y = int(((y - vertical_range[0])/increment))


     if current_websocket:
        coords = {"row": cell_y, "col": cell_x}
        print(f"Sending: {coords}")
        #asyncio.create_task(current_websocket.send(json.dumps(coords)))
        #loop = asyncio.get_event_loop()  # Get the main async loop
        asyncio.run_coroutine_threadsafe(send_coords(coords), event_loop)  # Bridge to async world

     print(f"Index finger cell coordinates: ({cell_x}, {cell_y})")
             


async def send_coords(coords):
    if current_websocket:
        try:
            await current_websocket.send(json.dumps(coords))
        except websockets.exceptions.ConnectionClosed:
            print("WebSocket connection closed")

def camera_loop():
    import os
    os.environ['OPENCV_AVFOUNDATION_SKIP_AUTH'] = '1'
    cap = cv2.VideoCapture(0)  
    with mp_hands.Hands(
        model_complexity=0,
        max_num_hands=1,
        min_detection_confidence=0.5,
        min_tracking_confidence=0.5,
    ) as hands:
        while cap.isOpened():
            success, frame = cap.read()
            if not success:
                print("Ignoring empty camera frame...")
                continue

            # TODO: check frame for hands
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            results = hands.process(frame_rgb)
            image_height, image_width, _ = frame_rgb.shape
            #print("image height: ",image_height)
            #print("image width: ",image_width)
            # Draw the hand annotations on the image
            if results.multi_hand_landmarks:
              for hand_landmarks in results.multi_hand_landmarks:
                  mp_drawing.draw_landmarks(
                  image=frame,
                  landmark_list=hand_landmarks,
                  connections=mp_hands.HAND_CONNECTIONS,
                  landmark_drawing_spec=mp_drawing_styles.get_default_hand_landmarks_style(),
                  connection_drawing_spec=mp_drawing_styles.get_default_hand_connections_style(),
              )
              if results.multi_hand_landmarks:
                #print(f"âœ‹ Detected {len(results.multi_hand_landmarks)} hand(s)")
                for hand_landmarks in results.multi_hand_landmarks:
                    #print('hand_landmarks:', hand_landmarks)
                    tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]
                    x_coord = int(tip.x * image_width)
                    y_coord = int(tip.y * image_height)
                    #print(f"Index finger tip coordinates: ({x_coord}, {y_coord})")
                    coords_to_graph(6, x_coord, y_coord, image_height, image_width)
                    
              
            draw_grid(6, image_height, image_width, frame)
            '''
            cv2.imshow("Hand Tracking", cv2.flip(frame, 1))
            if cv2.waitKey(1) & 0xFF == ord("q"):
                break
            '''
            cv2.waitKey(1)

    cap.release()


async def handle_client(websocket):
    global current_websocket
    current_websocket = websocket
    print("Javascript client connected")
    try:
        await websocket.wait_closed()
    except websockets.exceptions.ConnectionClosed:
        pass
    finally:
        print("Javascript client disconnected")
        current_websocket = None  



async def main():
    global event_loop
    event_loop = asyncio.get_running_loop()
    server = await websockets.serve(handle_client, "localhost", 8766)
    print("HeyyyyðŸŸ¥ðŸŸ¥ðŸŸ¥ðŸŸ¥ðŸŸ¥ðŸŸ¥ðŸŸ¥ðŸŸ¥WebSocket server started on ws://localhost:8766ðŸŸ¥ðŸŸ¥ðŸŸ¥ðŸŸ¥ðŸŸ¥ðŸŸ¥ðŸŸ¥ðŸŸ¥")  # ADD THIS LINE
    

    camera_thread = threading.Thread(target=camera_loop, daemon=True)
    camera_thread.start()

    try:
        await server.wait_closed()
    except KeyboardInterrupt:
        print("Shutting down...")
        server.close()







if __name__ == "__main__":
    asyncio.run(main())
